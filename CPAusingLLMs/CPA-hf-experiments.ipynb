{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed23b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from utils import load_cpa_dataset, save_pickle_file, load_pickle_file, load_cpa_dataset_column, calculate_f1_scores, decimal, map_cpa_to_labels, map_answers_column\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15be850",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"sotabv2\", \"t2dv2-webtables\"]\n",
    "\n",
    "model_name = \"upstage/SOLAR-0-70b-16bit\"\n",
    "mod = \"solar\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"hf_cache/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, load_in_8bit=True, device_map=\"auto\", cache_dir=\"hf_cache/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad2524",
   "metadata": {},
   "source": [
    "## Table prompt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7527786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-experiments prompt\n",
    "zero_template =\"\"\"### System:\n",
    "Answer the question based on the task and instructions below.\n",
    "Task: {task} {labels_joined}.\n",
    "Instructions: {instruction}\n",
    "\n",
    "### User:\n",
    "{mess}\n",
    "{input_string}\n",
    "\n",
    "### Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-experiments prompt\n",
    "few_template =\"\"\"### System:\n",
    "Answer the question based on the task and instructions below.\n",
    "Task: {task} {labels_joined}.\n",
    "Instructions: {instruction}\n",
    "\n",
    "{examples}\n",
    "\n",
    "### User:\n",
    "{mess}\n",
    "{input_string}\n",
    "\n",
    "### Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"\": \"Classify the relationship between two columns of a given table with one of the following relationships that are separated with comma:\",\n",
    "    \"-cpa\": \"Your task is to perform column property annotation (CPA), meaning that your task is to annotate the relationship between the leftmost column (name column) and a second column of a given table with only one of the following relationships that are separated with comma:\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a571d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = {\n",
    "    \"\": \"1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column 2: relationship. Don't return any relationship for the first column! 5. Answer only with labels from the provided label set!\",\n",
    "    \"-less-instructions\": \"1. For each column, select a relationship from the list that best represents the relationship between that column and the first column of the table. 2. Answer with only one selected relationship for each column with the format Column 2: relationship. Don't return any relationship for the first column! 3. Answer only with labels from the provided label set!\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5190c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message = {\n",
    "    \"\": \"Classify these table columns:\",\n",
    "    \"-annotate\": \"Please annotate the columns of the following table:\",\n",
    "    \"-determine\": \"Please determine the relationships for columns of this table:\",\n",
    "    \"-relationships\": \"Please classify the relationships between the first column and the other columns of this table:\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bc904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"-markdown-20\",False)\n",
    "    labels_joined = \", \".join([labels_to_text[l] for l in labels_to_text])\n",
    "    \n",
    "    for task in tasks:\n",
    "        for instruction in instructions:\n",
    "            for mess in last_message:\n",
    "                prompt_formulation = f\"{task}{instruction}{mess}\"\n",
    "                print(prompt_formulation)\n",
    "                \n",
    "                if f\"cpa-prompt-table{prompt_formulation}-0-shot.pkl\" not in os.listdir(f\"predictions/{dataset}/{mod}/\"):\n",
    "                    # Zero-shot\n",
    "                    prompt = PromptTemplate(template=zero_template, input_variables=['input_string', 'labels_joined', 'task', 'instruction', 'mess'])\n",
    "\n",
    "                    prompts = []\n",
    "                    model_answers = []\n",
    "\n",
    "                    for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "                        text_prompt = prompt.format(input_string=example.strip(), labels_joined=labels_joined, task=tasks[task], instruction=instructions[instruction], mess=last_message[mess])\n",
    "                        prompts.append(text_prompt) \n",
    "\n",
    "                        inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "                        output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=1000)\n",
    "                        model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))        \n",
    "\n",
    "                    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table{prompt_formulation}-0-shot.pkl\", model_answers)\n",
    "                    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table{prompt_formulation}-0-shot-prompts.pkl\", prompts)\n",
    "\n",
    "                if f\"cpa-prompt-table{prompt_formulation}-3-shot.pkl\" not in os.listdir(f\"predictions/{dataset}/{mod}/\"):\n",
    "                    # Few-shot: random\n",
    "                    for j in [1,3]:\n",
    "\n",
    "                        prompts = []\n",
    "                        model_answers = []\n",
    "                        prompt = PromptTemplate(template=few_template, input_variables=['input_string', 'examples', 'labels_joined', 'task', 'instruction', 'mess'])\n",
    "\n",
    "                        for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "\n",
    "                            random_examples = \"\"\"\"\"\"\n",
    "                            for i in range(0,j):\n",
    "                                index = random.randint(0, len(train_examples)-1)\n",
    "                                random_examples += f\"\"\"### User:\\n{last_message[mess]}\\n{train_examples[index].strip()}\\n\\n### Assistant:\\n{train_example_labels[index]}\\n\\n\"\"\"\n",
    "                            random_examples = random_examples.strip()\n",
    "\n",
    "                            text_prompt = prompt.format(input_string=example, examples=random_examples, labels_joined=labels_joined, task=tasks[task], instruction=instructions[instruction], mess=last_message[mess])\n",
    "                            prompts.append(text_prompt)\n",
    "\n",
    "                            inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "                            output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=1000)\n",
    "                            model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "                        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table{prompt_formulation}-{j}-shot.pkl\", model_answers)\n",
    "                        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table{prompt_formulation}-{j}-shot-prompts.pkl\", prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155cff5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b37b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table prompt evaluation\n",
    "print(f\"\\tPrecision)\\tRecall\\tMacro-F1\\tMicro-F1\\tOOV\")\n",
    "for nr in [0, 1, 3]:\n",
    "    preds = load_pickle_file(f'predictions/{dataset}/{mod}/cpa-prompt-table-{nr}-shot.pkl')\n",
    "    prompts = load_pickle_file(f'predictions/{dataset}/{mod}/cpa-prompt-table-{nr}-shot-prompts.pkl')\n",
    "\n",
    "    preds = [pred.replace(prompts[i], \"\") for i,pred in enumerate(preds)]\n",
    "    predictions, num = map_cpa_to_labels(preds,prompts)\n",
    "    \n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if \"-\" in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    \n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d80712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
