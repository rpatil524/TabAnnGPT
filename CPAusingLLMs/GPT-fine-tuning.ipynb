{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from utils import map_cpa_to_labels, calculate_f1_scores, save_pickle_file, load_cpa_dataset_column, load_pickle_file, load_cpa_dataset, decimal, map_answers_column, map_cta_labels,load_cta_dataset\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe0620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load env file with API KEY using full path\n",
    "config = dotenv_values(\"/full/path/to/file/key.env\")\n",
    "os.environ['OPENAI_API_KEY'] = config[\"OPENAI_API_KEY\"]\n",
    "OPENAI_API_KEY = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ecda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fine-tuning job\n",
    "# Example: fine-tune on cpa task only:\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"data/ft-data/cpa-ft/cpa-train-20-ft.jsonl\",\n",
    "  validation_file=\"data/ft-data/cpa-ft/cpa-val-ft.jsonl\",\n",
    "  model=\"gpt-3.5-turbo-0613\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2db194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuned model names as keys\n",
    "fine_tuning_models = {\n",
    "    \"\": \"cta-ft-gpt-3.5-turbo-0613\",\n",
    "    \"\": \"cpa-ft-gpt-3.5-turbo-0613\",\n",
    "    \"\": \"ctacpa-ft-gpt-3.5-turbo-0613\",\n",
    "    \"\": \"ctacpa-small-ft-gpt-3.5-turbo-0613\",\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab68a87",
   "metadata": {},
   "source": [
    "### Test CPA task with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c2d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zero-shot\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"-markdown-20\",False)\n",
    "\n",
    "    for model_name in ft_models:\n",
    "        print(model_name)\n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "        \n",
    "        for nr in [0]:\n",
    "            print(nr)\n",
    "            for task in tasks:\n",
    "                for instruction in instructions:\n",
    "                    for mess in last_message:\n",
    "                        print(f\"cpa-chat-table-{nr}-shot{task}{instruction}{mess}\")\n",
    "                        preds = []\n",
    "                        \n",
    "                        #For each combination run prediction\n",
    "                        for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "                            messages = []\n",
    "                            messages.append(SystemMessage(content=f\"Your task is to classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\"))\n",
    "                            messages.append(SystemMessage(content=\"Your instructions are: 1. For each column, select a relationship from the list that best represents the relationship between that column and the first column of the table. 2. Answer with only one selected relationship for each column with the format Column 2: relationship. Don't return any relationship for the first column! 3. Answer only with labels from the provided label set!\"))\n",
    "\n",
    "                            for i in range(0,nr):\n",
    "                                index = random.randint(0, len(train_examples)-1)\n",
    "                                messages.append(HumanMessage(content=f\"Please classify the relationships between the first column and the other columns of this table:\\n{train_examples[index]}\"))\n",
    "                                messages.append(AIMessage(content=f\"{train_example_labels[index]}\"))\n",
    "\n",
    "                            messages.append(HumanMessage(content=f\"Please classify the relationships between the first column and the other columns of this table:\\n{example}\"))\n",
    "                            \n",
    "                            res = chat(messages)\n",
    "                            preds.append(res.content)\n",
    "                        save_pickle_file(f\"predictions/{dataset}/{ft_models[model_name]}/cpa-chat-table-{nr}-shot-markdown.pkl\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "for nr in [0]:\n",
    "    preds = load_pickle_file(f\"predictions/{dataset}/{ft_models[model_name]}/cpa-chat-table-{nr}-shot-markdown.pkl\")\n",
    "    predictions, num = map_cpa_to_labels(preds, test, text_to_label)\n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if '-' in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f0a4d",
   "metadata": {},
   "source": [
    "### Test CTA task with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b80b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"-markdown-20\")\n",
    "\n",
    "    for model_name in ft_models:\n",
    "        print(ft_models[model_name])\n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "\n",
    "        #Zero-shot\n",
    "        for nr in [0]:\n",
    "            preds = []\n",
    "\n",
    "            for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                messages = []\n",
    "                messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\")) #labels_in_prompts[j]\n",
    "                messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For the required columns, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column 1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "\n",
    "                for i in range(0,nr):\n",
    "                    index = random.randint(0, len(train_examples)-1)\n",
    "                    messages.append(HumanMessage(content=f\"Classify these table columns:\\n{train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_example_labels[index]}\"))\n",
    "\n",
    "                messages.append(HumanMessage(content=f\"Classify these table columns:\\n{example}\"))\n",
    "                res = chat(messages)\n",
    "                preds.append(res.content)\n",
    "            save_pickle_file(f\"predictions/{dataset}/{ft_models[model_name]}/chat-table-{nr}-shot-markdown.pkl\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "for nr in [0]:\n",
    "    preds = load_pickle_file(f\"predictions/{dataset}/{ft_models[model_name]}/chat-table-{nr}-shot-markdown.pkl\")\n",
    "    predictions, num, oov_indices, oov, oov_table_indices, oov_tablecolumn_indices, _, _ = map_cta_labels(preds, test, text_to_label)\n",
    "    labels = [l for l in labels if l!=\"\"]\n",
    "    \n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if '-' in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f70564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
