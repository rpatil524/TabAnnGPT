{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fa1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sienna\n",
    "# import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef08e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "from utils import clean_text, save_pickle_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the SOTAB V2 CTA tables\n",
    "# Tables can be downloaded at the webpage: https://webdatacommons.org/structureddata/sotab/v2/\n",
    "table_path = \"../../../SOTAB-v2/CTA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_train_gt = pd.read_csv(\"data/sets/sotab_v2_cta_train-subset.csv\")\n",
    "cta_val_gt = pd.read_csv(\"data/sets/sotabv2_cta_validation-subset.csv\")\n",
    "cta_test_gt = pd.read_csv(\"data/sets/sotabv2_cta_test-subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4502ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {'train':{}, 'val':{}, 'test':{}}\n",
    "for index, row in cta_train_gt.iterrows():\n",
    "    if row[\"table_name\"] not in gt['train']:\n",
    "        gt['train'][row[\"table_name\"]] = {}\n",
    "    gt['train'][row[\"table_name\"]][row[\"column_index\"]] = [row[\"label\"], row[\"column_type\"]]\n",
    "\n",
    "for index, row in cta_val_gt.iterrows():\n",
    "    if row[\"table_name\"] not in gt['val']:\n",
    "        gt['val'][row[\"table_name\"]] = {}\n",
    "    gt['val'][row[\"table_name\"]][row[\"column_index\"]] = [row[\"label\"], row[\"column_type\"]]\n",
    "    \n",
    "for index, row in cta_test_gt.iterrows():\n",
    "    if row[\"table_name\"] not in gt['test']:\n",
    "        gt['test'][row[\"table_name\"]] = {}\n",
    "    gt['test'][row[\"table_name\"]][row[\"column_index\"]] = [row[\"label\"], row[\"column_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_text = sienna.load(\"data/labels_to_text_sotabv2-subsetu-cta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown Format\n",
    "def get_table(file_name):\n",
    "    \n",
    "    if file_name in cta_train_gt[\"table_name\"].tolist():\n",
    "        path = f'{table_path}Train/{file_name}'\n",
    "        split = 'train'\n",
    "    elif file_name in cta_val_gt[\"table_name\"].tolist():\n",
    "        path = f'{table_path}Validation/{file_name}'\n",
    "        split = 'val'\n",
    "    else:\n",
    "        path = f'{table_path}Test/{file_name}'\n",
    "        split = 'test'\n",
    "    \n",
    "    df = pd.read_json(path, compression='gzip', lines=True)\n",
    "    \n",
    "    ordered_labels = []\n",
    "    ordered_types = []\n",
    "    \n",
    "    for i, _ in enumerate(df.columns):\n",
    "        if i in gt[split][file_name]:\n",
    "            ordered_labels.append(gt[split][file_name][i][0])\n",
    "            ordered_types.append(gt[split][file_name][i][1])\n",
    "        else:\n",
    "            # Unlabeled column: added as context\n",
    "            # Comment all the else section if context not wanted\n",
    "            ordered_labels.append(\"\")\n",
    "            ordered_types.append(\"\")\n",
    "            \n",
    "    cleaned_columns = []\n",
    "\n",
    "    for i, c in enumerate(df.columns):\n",
    "        if i in gt[split][file_name]:\n",
    "            cleaned_rows = []\n",
    "            for row in df.iloc[:, i].tolist():\n",
    "                cleaned = \" \".join(clean_text(row).split()[:20]) #select 20 words\n",
    "                if cleaned != \"\":\n",
    "                    cleaned_rows.append(cleaned)\n",
    "            cleaned_columns.append(cleaned_rows)\n",
    "\n",
    "        else:\n",
    "            # Unlabeled column: added as context\n",
    "            # Comment all the else section if context not wanted\n",
    "            cleaned_rows = []\n",
    "            for row in df.iloc[:, i].tolist():\n",
    "                cleaned = \" \".join(clean_text(row).split()[:20]) #select 20 words\n",
    "                if cleaned != \"\":\n",
    "                    cleaned_rows.append(cleaned)\n",
    "            cleaned_columns.append(cleaned_rows)\n",
    "\n",
    "    table_list_df = []\n",
    "\n",
    "    # Add empty if not len 5\n",
    "    for i, col_rows in enumerate(cleaned_columns):\n",
    "        if len(col_rows) < 5: # number of rows\n",
    "            for j in range(5-len(col_rows)):\n",
    "                cleaned_columns[i].append(\"\")\n",
    "    for j in range(5):\n",
    "        new_row = []\n",
    "        for cleaned_column in cleaned_columns:\n",
    "            new_row.append(cleaned_column[j])\n",
    "        table_list_df.append(new_row)\n",
    "\n",
    "    # Markdown format\n",
    "    df_new = pd.DataFrame(table_list_df, columns=[ f\"Column {i+1}\" for i in range(len(cleaned_columns))])\n",
    "    # uncomment for knowledge generation set (-kg):\n",
    "    # df_new = pd.DataFrame(table_list_df, columns=[labels_to_text[ordered_labels[i]] for i in range(len(cleaned_columns))])\n",
    "\n",
    "    table_string = df_new.to_markdown(index=False)\n",
    "    column_names = [ f\"Column {i+1}\" for i in range(len(cleaned_columns))]\n",
    "\n",
    "    return table_string, list(ordered_labels), ordered_types, file_name.split(\"_\")[0], column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bda315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/698 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 698/698 [00:33<00:00, 20.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples = []\n",
    "for table in tqdm.tqdm(gt['train'], total=len(gt['train'])):\n",
    "    tab_str, labels, types, domains, col_names = get_table(table)\n",
    "    train_examples.append([table, tab_str, labels, domains, types, col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefe98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:11<00:00, 22.98it/s]\n"
     ]
    }
   ],
   "source": [
    "val_examples = []\n",
    "for table in tqdm.tqdm(gt['val'], total=len(gt['val'])):\n",
    "    tab_str, labels, types, domains, col_names = get_table(table)\n",
    "    val_examples.append([table, tab_str, labels, domains, types, col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b48adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:16<00:00, 22.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test_examples = []\n",
    "for table in tqdm.tqdm(gt['test'], total=len(gt['test'])):\n",
    "    tab_str, labels, types, domains, col_names = get_table(table)\n",
    "    test_examples.append([table, tab_str, labels, domains, types, col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2605ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle_file(\"data/sotabv2-subsetu-cta-train-random-20.pkl\", train_examples)\n",
    "save_pickle_file(\"data/sotabv2-subsetu-cta-val.pkl\", val_examples)\n",
    "save_pickle_file(\"data/sotabv2-subsetu-cta-test.pkl\", test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49907726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save knowledge generation set\n",
    "save_pickle_file(\"data/sotabv2-subsetu-cta-train-random-20-kg.pkl\", train_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
