{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import sienna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d058a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "from utils import clean_text, save_pickle_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_df(df):\n",
    "    df[\"labels\"] = df[\"labels\"].apply(lambda x: eval(x))\n",
    "    df[\"table\"] = df[\"table\"].apply(lambda x: eval(x))\n",
    "    df[\"headers\"] = df[\"headers\"].apply(lambda x: eval(x))\n",
    "    return df                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cta_train_gt = pd.read_csv('data/sets/train_wikitables_subset_20.csv')\n",
    "cta_dev_gt = pd.read_csv('data/sets/dev_wikitables_subset_2.csv')\n",
    "cta_test_gt = pd.read_csv('data/sets/test_wikitables_subset_2.csv')\n",
    "\n",
    "cta_train_gt = eval_df(cta_train_gt)\n",
    "cta_dev_gt = eval_df(cta_dev_gt)\n",
    "cta_test_gt = eval_df(cta_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbecef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_text = sienna.load(\"data/labels_to_text_wikitables-2-cta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbabf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 809/809 [00:00<00:00, 1116.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for index, row in tqdm.tqdm(cta_train_gt.iterrows(), total=len(cta_train_gt)):\n",
    "\n",
    "    table = row[\"table\"] #table values\n",
    "    ordered_labels = row[\"labels\"] # column labels\n",
    "\n",
    "    cleaned_columns = []\n",
    "    for column_index, c in enumerate(table):\n",
    "        cleaned_rows = []\n",
    "        for row_ in table[column_index]:\n",
    "            cleaned = \" \".join(clean_text(row_[1][1]).split()[:20])\n",
    "            if cleaned != \"\":\n",
    "                cleaned_rows.append(cleaned)\n",
    "        cleaned_columns.append(cleaned_rows)\n",
    "\n",
    "    table_list_df = []\n",
    "    # Add empty if not len 5\n",
    "    for i, col_rows in enumerate(cleaned_columns):\n",
    "        if len(col_rows) < 5: # number of rows\n",
    "            for j in range(5-len(col_rows)):\n",
    "                cleaned_columns[i].append(\"\")\n",
    "    \n",
    "    # Create table list for dataframe\n",
    "    for j in range(5):\n",
    "        new_row = []\n",
    "        for cleaned_column in cleaned_columns:\n",
    "            new_row.append(cleaned_column[j])\n",
    "        table_list_df.append(new_row)\n",
    "\n",
    "    # Markdown format\n",
    "    df_new = pd.DataFrame(table_list_df, columns=[ f\"Column {i+1}\" for i in range(len(cleaned_columns))])\n",
    "    # uncomment for knowledge generation set (-kg):\n",
    "    # df_new = pd.DataFrame(table_list_df, columns=[\", \".join([labels_to_text[l] for l in ordered_labels[i]])  for i in range(len(cleaned_columns))])\n",
    "\n",
    "    df_num = df_new.select_dtypes(include=['number'])\n",
    "\n",
    "    column_types = []\n",
    "\n",
    "    for column_name in df_new.columns:\n",
    "        if column_name in df_num.columns:\n",
    "            column_types.append(\"numerical\")\n",
    "        else:\n",
    "            column_types.append(\"textual\")\n",
    "\n",
    "    table_string = df_new.to_markdown(index=False)\n",
    "    column_names = [ f\"Column {i+1}\" for i in range(len(cleaned_columns))]\n",
    "    \n",
    "    train.append([row[\"table_name\"], table_string, ordered_labels, eval(row[\"domains\"]), column_types, row[\"page_title\"], row[\"section_title\"], row[\"headers\"], column_names ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [00:00<00:00, 1001.55it/s]\n"
     ]
    }
   ],
   "source": [
    "dev = []\n",
    "for index, row in tqdm.tqdm(cta_dev_gt.iterrows(), total=len(cta_dev_gt)):\n",
    "\n",
    "    table = row[\"table\"] #table values\n",
    "    ordered_labels = row[\"labels\"] # column labels\n",
    "\n",
    "    cleaned_columns = []\n",
    "    for column_index, c in enumerate(table):\n",
    "        cleaned_rows = []\n",
    "        for row_ in table[column_index]:\n",
    "            cleaned = \" \".join(clean_text(row_[1][1]).split()[:20])\n",
    "            if cleaned != \"\":\n",
    "                cleaned_rows.append(cleaned)\n",
    "        cleaned_columns.append(cleaned_rows)\n",
    "\n",
    "    table_list_df = []\n",
    "    # Add empty if not len 5\n",
    "    for i, col_rows in enumerate(cleaned_columns):\n",
    "        if len(col_rows) < 5: # number of rows\n",
    "            for j in range(5-len(col_rows)):\n",
    "                cleaned_columns[i].append(\"\")\n",
    "    \n",
    "    # Create table list for dataframe\n",
    "    for j in range(5):\n",
    "        new_row = []\n",
    "        for cleaned_column in cleaned_columns:\n",
    "            new_row.append(cleaned_column[j])\n",
    "        table_list_df.append(new_row)\n",
    "\n",
    "    # Markdown format\n",
    "    df_new = pd.DataFrame(table_list_df, columns=[ f\"Column {i+1}\" for i in range(len(cleaned_columns))])\n",
    "    df_num = df_new.select_dtypes(include=['number'])\n",
    "\n",
    "    column_types = []\n",
    "\n",
    "    for column_name in df_new.columns:\n",
    "        if column_name in df_num.columns:\n",
    "            column_types.append(\"numerical\")\n",
    "        else:\n",
    "            column_types.append(\"textual\")\n",
    "\n",
    "    table_string = df_new.to_markdown(index=False)\n",
    "    column_names = [ f\"Column {i+1}\" for i in range(len(cleaned_columns))]\n",
    "    \n",
    "    dev.append([row[\"table_name\"], table_string, ordered_labels, eval(row[\"domains\"]), column_types, row[\"page_title\"], row[\"section_title\"], row[\"headers\"], column_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02348e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [00:00<00:00, 707.10it/s]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for index, row in tqdm.tqdm(cta_test_gt.iterrows(), total=len(cta_test_gt)):\n",
    "\n",
    "    table = row[\"table\"] #table values\n",
    "    ordered_labels = row[\"labels\"] # column labels\n",
    "\n",
    "    cleaned_columns = []\n",
    "    for column_index, c in enumerate(table):\n",
    "        cleaned_rows = []\n",
    "        for row_ in table[column_index]:\n",
    "            cleaned = \" \".join(clean_text(row_[1][1]).split()[:20])\n",
    "            if cleaned != \"\":\n",
    "                cleaned_rows.append(cleaned)\n",
    "        cleaned_columns.append(cleaned_rows)\n",
    "\n",
    "    table_list_df = []\n",
    "    # Add empty if not len 5\n",
    "    for i, col_rows in enumerate(cleaned_columns):\n",
    "        if len(col_rows) < 5: # number of rows\n",
    "            for j in range(5-len(col_rows)):\n",
    "                cleaned_columns[i].append(\"\")\n",
    "    \n",
    "    # Create table list for dataframe\n",
    "    for j in range(5):\n",
    "        new_row = []\n",
    "        for cleaned_column in cleaned_columns:\n",
    "            new_row.append(cleaned_column[j])\n",
    "        table_list_df.append(new_row)\n",
    "\n",
    "    # Markdown format\n",
    "    df_new = pd.DataFrame(table_list_df, columns=[ f\"Column {i+1}\" for i in range(len(cleaned_columns))])\n",
    "    df_num = df_new.select_dtypes(include=['number'])\n",
    "\n",
    "    column_types = []\n",
    "\n",
    "    for column_name in df_new.columns:\n",
    "        if column_name in df_num.columns:\n",
    "            column_types.append(\"numerical\")\n",
    "        else:\n",
    "            column_types.append(\"textual\")\n",
    "\n",
    "    table_string = df_new.to_markdown(index=False)\n",
    "    column_names = [ f\"Column {i+1}\" for i in range(len(cleaned_columns))]\n",
    "    \n",
    "    test.append([row[\"table_name\"], table_string, ordered_labels, eval(row[\"domains\"]), column_types, row[\"page_title\"], row[\"section_title\"], row[\"headers\"], column_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_pickle_file('data/wikitables-2-cta-train-random-20-kg.pkl',train)\n",
    "save_pickle_file('data/wikitables-2-cta-train-random-20.pkl',train)\n",
    "save_pickle_file('data/wikitables-2-cta-val.pkl',dev)\n",
    "save_pickle_file('data/wikitables-2-cta-test.pkl', test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
