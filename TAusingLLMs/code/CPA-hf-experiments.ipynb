{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed23b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from utils import load_cpa_dataset, save_pickle_file, load_pickle_file, load_cpa_dataset_column, calculate_f1_scores, decimal, map_cpa_to_labels, map_answers_column\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"#3,4,5,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15be850",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"sotabv2\", \"t2dv2-webtables\"]\n",
    "\n",
    "# StableBeluga7B\n",
    "model_name = \"stabilityai/StableBeluga-7B\"\n",
    "mod = \"stablebeluga7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"hf_cache/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map=\"auto\", cache_dir=\"hf_cache/\")\n",
    "\n",
    "# SOLAR\n",
    "# model_name = \"upstage/SOLAR-0-70b-16bit\"\n",
    "# mod = \"solar\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"hf_cache/\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, load_in_8bit=True, device_map=\"auto\", cache_dir=\"hf_cache/\", temperature=0, do_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64800a3",
   "metadata": {},
   "source": [
    "## Column prompt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_template = \"\"\"Answer the question based on the task and instructions below.\n",
    "Task: Classify the relationship between two columns with one of the following classes that are separated with comma: {labels_joined}.\n",
    "Instructions: 1. Look at the two columns and the classes given to you 2. Look at their values in detail. 3. Select a class that best represents the relationship between the two columns. 4. Answer with only one class.\n",
    "Column1: {column_1}\n",
    "Column2: {column_2}\n",
    "Class:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed944c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_template = \"\"\"Answer the question based on the task and instructions below.\n",
    "Task: Classify the relationship between two columns with one of the following classes that are separated with comma: {labels_joined}.\n",
    "Instructions: 1. Look at the two columns and the classes given to you 2. Look at their values in detail. 3. Select a class that best represents the relationship between the two columns. 4. Answer with only one class.\n",
    "{examples}\n",
    "Column1: {column_1}\n",
    "Column2: {column_2}\n",
    "Class:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7def64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    examples, labels, train_examples, train_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset_column(dataset,\"\")\n",
    "    all_labels = [labels_to_text[l] for l in labels_to_text]\n",
    "\n",
    "    # Zero-shot\n",
    "    prompt = PromptTemplate(template=zero_template, input_variables=['labels_joined', 'column_1', 'column_2'])\n",
    "    prompts = []\n",
    "    model_answers = []\n",
    "\n",
    "    for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "        text_prompt = prompt.format(labels_joined=labels_joined, column_1=example[0], column_2=example[1])\n",
    "        inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "        \n",
    "        prompts.append(text_prompt)\n",
    "        model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-column-0-shot.pkl\", model_answers)\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-column-0-shot-prompts.pkl\", prompts)\n",
    "\n",
    "    # Few-shot\n",
    "    for j in [1, 3]:\n",
    "        \n",
    "        prompts = []\n",
    "        model_answers = []\n",
    "        prompt = PromptTemplate(template=few_template, input_variables=['column_1', 'column_2', 'examples', 'labels_joined'])\n",
    "\n",
    "        for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "\n",
    "            random_examples = \"\"\"\"\"\"\n",
    "\n",
    "            for i in range(0,j):\n",
    "                index = random.randint(0, len(train_examples)-1)\n",
    "                random_examples += f\"\"\"Column1: {train_examples[index][0]}\\nColumn2:{train_examples[index][1]}\\nClass: {train_labels[index]}\\n\"\"\"\n",
    "\n",
    "            random_examples = random_examples.strip()\n",
    "\n",
    "            text_prompt = prompt.format(column_1=example[0], column_2=example[1], examples=random_examples, labels_joined=labels_joined)\n",
    "            prompts.append(text_prompt)\n",
    "\n",
    "            inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "            model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))            \n",
    "            \n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-column-{j}-shot.pkl\", model_answers)\n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-column-{j}-shot-prompts.pkl\", prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad2524",
   "metadata": {},
   "source": [
    "## Table prompt experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e863df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_template = \"\"\"Answer the question based on the task and instructions below.\n",
    "Task: Classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\n",
    "Instructions: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column2: relationship. Don't return any relationship for the first column!\n",
    "Table:\n",
    "{input_string}Class:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f765b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_template = \"\"\"Answer the question based on the task and instructions below.\n",
    "Task: Classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\n",
    "Instructions: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column2: relationship. Don't return any relationship for the first column!\n",
    "{examples}\n",
    "Table:\n",
    "{input_string}Class:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"\",False)\n",
    "    labels_joined = \", \".join([labels_to_text[l] for l in labels_to_text])\n",
    "\n",
    "    # Zero-shot\n",
    "    prompt = PromptTemplate(template=zero_template, input_variables=['input_string', 'labels_joined'])\n",
    "            \n",
    "    prompts = []\n",
    "    model_answers = []\n",
    "            \n",
    "    for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "        text_prompt = prompt.format(input_string=example.strip(), labels_joined=labels_joined)\n",
    "        prompts.append(text_prompt) \n",
    "\n",
    "        inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "        model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))        \n",
    "\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-0-shot.pkl\", model_answers)\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-0-shot-prompts.pkl\", prompts)\n",
    "\n",
    "    # Few-shot: random\n",
    "    for j in [1, 3]:\n",
    "        \n",
    "        prompts = []\n",
    "        model_answers = []\n",
    "        prompt = PromptTemplate(template=few_template, input_variables=['input_string', 'examples', 'labels_joined'])\n",
    "\n",
    "        for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "\n",
    "            random_examples = \"\"\"\"\"\"\n",
    "            for i in range(0,j):\n",
    "                index = random.randint(0, len(train_examples)-1)\n",
    "                random_examples += f\"\"\"Table:\\n{train_examples[index]}Class:\\n{train_example_labels[index]}\\n\"\"\"\n",
    "            random_examples = random_examples.strip()\n",
    "\n",
    "            text_prompt = prompt.format(input_string=example, examples=random_examples, labels_joined=labels_joined)\n",
    "            prompts.append(text_prompt)\n",
    "            \n",
    "            inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "            model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "            \n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-{j}-shot.pkl\", model_answers)\n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-{j}-shot-prompts.pkl\", prompts)\n",
    "\n",
    "    # Few-shot: similar\n",
    "    prompts = []\n",
    "    model_answers = []\n",
    "    prompt = PromptTemplate(template=few_template, input_variables=['input_string', 'examples', 'labels_joined'])\n",
    "    examples_demonstrations = load_pickle_file(f\"embeddings/cpa-examples_demonstrations_{dataset}.pkl\")\n",
    "\n",
    "    for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "        random_examples = \"\"\"\"\"\"\n",
    "        for index in examples_demonstrations[i][-3:]:\n",
    "            random_examples += f\"\"\"Table:\\n{train_examples[index]}Class:\\n{train_example_labels[index]}\\n\"\"\"\n",
    "        random_examples = random_examples.strip()\n",
    "\n",
    "        text_prompt = prompt.format(input_string=example, examples=random_examples, labels_joined=labels_joined)\n",
    "        prompts.append(text_prompt)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "        model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-3-similar-shot.pkl\", model_answers)\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-3-similar-shot-prompts.pkl\", prompts)\n",
    "\n",
    "    # Few-shot: corner cases\n",
    "    prompts = []\n",
    "    model_answers = []\n",
    "    prompt = PromptTemplate(template=few_template, input_variables=['input_string', 'examples', 'labels_joined'])\n",
    "    cc_demonstrations = load_pickle_file(f\"embeddings/cpa-cc_examples_demonstrations_{dataset}.pkl\")\n",
    "\n",
    "    for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "        random_examples = \"\"\"\"\"\"\n",
    "        for index in cc_demonstrations[i][:2]:\n",
    "            random_examples += f\"\"\"Table:\\n{train_examples[index]}Class:\\n{train_example_labels[index]}\\n\"\"\"\n",
    "        random_examples = random_examples.strip()\n",
    "\n",
    "        text_prompt = prompt.format(input_string=example, examples=random_examples, labels_joined=labels_joined)\n",
    "        prompts.append(text_prompt)\n",
    "\n",
    "        inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "        model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-2-cc-shot.pkl\", model_answers)\n",
    "    save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-table-2-cc-shot-prompts.pkl\", prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d766844",
   "metadata": {},
   "source": [
    "### Two-step approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd67e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_template = \"\"\"Your task is to classify a table into one of these domains: {domains_list}.\n",
    "Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. Decide the domain that best represents the table. 4. Answer with one domain.\n",
    "{examples}\n",
    "Classify this table: {input_string}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the task and instructions below.\n",
    "Task: Classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\n",
    "Instructions: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column2: relationship. Don't return any relationship for the first column!\n",
    "{examples}\n",
    "Table:\n",
    "{input_string}\n",
    "Class:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_table_prediction(table_pred, domains):\n",
    "    cleaned_table_pred=\"-\"\n",
    "    for dom in domains:\n",
    "        if dom in table_pred:\n",
    "            cleaned_table_pred = dom\n",
    "            break\n",
    "    return cleaned_table_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"\",False)\n",
    "    labels_joined = \", \".join([labels_to_text[l] for l in labels_to_text])\n",
    "\n",
    "    domains = set(train_table_type_labels)\n",
    "\n",
    "    labels_dict = {}\n",
    "    for dom in domains:\n",
    "        f = open(f\"data/labels/{dataset}_cpa_{dom}_labels.txt\", 'r')\n",
    "        t = [line.split('\\n')[0] for line in f.readlines()]\n",
    "        labels_dict[dom] = t\n",
    "\n",
    "    domains_list = \", \".join(domains)\n",
    "\n",
    "    for j in [0, 1, 3]:\n",
    "        \n",
    "        # Step 1\n",
    "        table_prompts = []\n",
    "        table_model_answers = []\n",
    "        # Step 2\n",
    "        prompts = []\n",
    "        model_answers = []\n",
    "\n",
    "        for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "            prompt = PromptTemplate(template=table_template, input_variables=['input_string', 'domains_list', 'examples'])\n",
    "\n",
    "            random_examples = \"\"\"\"\"\"\n",
    "\n",
    "            for i in range(0,j):\n",
    "                index = random.randint(0, len(train_examples)-1)\n",
    "                random_examples += f\"\"\"Classify this table:{train_examples[index]}Class: {train_table_type_labels[index]}\\n\"\"\"\n",
    "\n",
    "            random_examples = random_examples.strip()\n",
    "\n",
    "            text_prompt = prompt.format(input_string=example, examples=random_examples, domains_list=domains_list)\n",
    "            table_prompts.append(text_prompt)\n",
    "\n",
    "            inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "            # output = model.generate(**inputs, top_k=0, max_new_tokens=256, use_cache=True)\n",
    "            answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            table_model_answers.append(answer)\n",
    "\n",
    "            clean_prediction = get_clean_table_prediction(answer.replace(text_prompt, \"\").strip(), domains)\n",
    "\n",
    "            prompt = PromptTemplate(template=template, input_variables=['input_string','labels_joined', 'examples'])\n",
    "\n",
    "            random_examples = \"\"\"\"\"\"\n",
    "\n",
    "            if clean_prediction != \"-\":\n",
    "                labels_dom = \", \".join([labels_to_text[l] for l in labels_dict[clean_prediction]])\n",
    "\n",
    "                for m in range(0,j):\n",
    "                    index = random.choice([j for j, e in enumerate(train_table_type_labels) if e == clean_prediction])\n",
    "                    random_examples += f\"\"\"Table:\\n{train_examples[index]}Class:\\n{train_example_labels[index]}\\n\"\"\"\n",
    "                random_examples = random_examples.strip()\n",
    "\n",
    "            else:\n",
    "                labels_dom = labels_joined\n",
    "\n",
    "            text_prompt = prompt.format(input_string=example, examples=random_examples, labels_joined=labels_dom)\n",
    "            prompts.append(text_prompt)\n",
    "\n",
    "            # pdb.set_trace()\n",
    "\n",
    "            inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output = model.generate(**inputs, do_sample=True, top_p=0.95, top_k=0, max_new_tokens=256)\n",
    "            model_answers.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-two-step-{j}-shot-step1.pkl\", table_model_answers)\n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-two-step-{j}-shot-step1-prompts.pkl\", table_prompts)\n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-two-step-{j}-shot-step2.pkl\", model_answers)\n",
    "        save_pickle_file(f\"predictions/{dataset}/{mod}/cpa-prompt-two-step-{j}-shot-step2-prompts.pkl\", prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155cff5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column prompt evaluation\n",
    "print(f\"\\tPrecision)\\tRecall\\tMacro-F1\\tMicro-F1\\tOOV\")\n",
    "for nr in [0, 1, 3]:\n",
    "    preds = load_pickle_file(f'predictions/{dataset}/{model}/cpa-prompt-column-{nr}-shot.pkl')\n",
    "    prompts = load_pickle_file(f'predictions/{dataset}/{model}/cpa-prompt-column-{nr}-shot-prompts.pkl')\n",
    "\n",
    "    preds = [pred.replace(prompts[i], \"\") for i,pred in enumerate(preds)]\n",
    "    predictions, num = map_answers_column(preds,prompts)\n",
    "    \n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if \"-\" in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    \n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b37b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table prompt evaluation\n",
    "print(f\"\\tPrecision)\\tRecall\\tMacro-F1\\tMicro-F1\\tOOV\")\n",
    "for nr in [0, 1, 3, \"3-similar\", \"2-cc\"]:\n",
    "    preds = load_pickle_file(f'predictions/{dataset}/{model}/cpa-prompt-table-{nr}-shot.pkl')\n",
    "    prompts = load_pickle_file(f'predictions/{dataset}/{model}/cpa-prompt-table-{nr}-shot-prompts.pkl')\n",
    "\n",
    "    preds = [pred.replace(prompts[i], \"\") for i,pred in enumerate(preds)]\n",
    "    predictions, num = map_cpa_to_labels(preds,prompts)\n",
    "    \n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if \"-\" in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    \n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d80712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
