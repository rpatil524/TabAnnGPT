{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307f1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from utils import map_cta_labels, map_answers_column, map_sportstables, calculate_f1_scores, save_pickle_file, load_cta_dataset, load_pickle_file, load_cta_dataset_column, decimal\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fe0620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load env file with API KEY using full path\n",
    "config = dotenv_values(\"/full/path/to/file/key.env\")\n",
    "os.environ['OPENAI_API_KEY'] = config[\"OPENAI_API_KEY\"]\n",
    "OPENAI_API_KEY = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12131723",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"sotabv2\", \"t2dv2-webtables\", \"sportstables\"]\n",
    "models = [\"gpt-3.5-turbo-0301\", \"gpt-4-0613\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d65b43",
   "metadata": {},
   "source": [
    "## Column-prompts experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4cddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    \n",
    "    for dataset in datasets[:2]:\n",
    "        print(dataset)\n",
    "        # Load dataset\n",
    "        examples, labels, train_examples, train_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset_column(dataset,\"\")\n",
    "\n",
    "        # Load embeddings\n",
    "        train_embeddings = load_pickle_file(f\"embeddings/train_embeddings_{dataset}-column.pkl\")\n",
    "        test_embeddings = load_pickle_file(f\"embeddings/test_embeddings_{dataset}-column.pkl\")\n",
    "        examples_demonstrations = load_pickle_file(f\"embeddings/examples_demonstrations_{dataset}-column.pkl\")\n",
    "\n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "        \n",
    "        #Zero-shot and Few-shot random demonstrations:\n",
    "        for nr in [0, 1, 5]:\n",
    "            preds = []\n",
    "\n",
    "            for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "                messages = []\n",
    "                messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate a given column with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "                messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the column and the labels given to you. 2. Examine the values of the column. 3. Select a label that best represents the meaning of the column. 4. Answer with the selected label. 5. Answer only with labels from the provided label set!\"))\n",
    "\n",
    "                for i in range(0,nr):\n",
    "                    index = random.randint(0, len(train_examples)-1)\n",
    "                    messages.append(HumanMessage(content=f\"Classify this column: {train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_labels[index]}\"))\n",
    "\n",
    "                messages.append(HumanMessage(content=f\"Classify this column: {example}\"))\n",
    "                res = chat(messages)\n",
    "                preds.append(res.content)\n",
    "            save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-column-{nr}-shot.pkl\", preds)\n",
    "\n",
    "        # Few-shot similar demonstrations\n",
    "        for nr in [1, 5]:\n",
    "            preds = []\n",
    "\n",
    "            for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                messages = []\n",
    "                messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate a given column with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "                messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the column and the labels given to you. 2. Examine the values of the column. 3. Select a label that best represents the meaning of the column. 4. Answer with the selected label. 5. Answer only with labels from the provided label set!\"))#\n",
    "\n",
    "                for index in examples_demonstrations[i][-nr:]:\n",
    "                    messages.append(HumanMessage(content=f\"Classify this column: {train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_labels[index]}\"))\n",
    "\n",
    "                messages.append(HumanMessage(content=f\"Classify this column: {example}\"))\n",
    "                res = chat(messages)\n",
    "                preds.append(res.content)\n",
    "            save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-column-{nr}-similar-shot.pkl\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d98d1",
   "metadata": {},
   "source": [
    "## Table-prompts experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147705c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    for dataset in datasets[:2]:\n",
    "        print(dataset)\n",
    "        # Load dataset\n",
    "        examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"\")\n",
    "        examples_demonstrations = load_pickle_file(f\"embeddings/examples_demonstrations_{dataset}.pkl\")\n",
    "        cc_examples_demonstratons = load_pickle_file(f\"embeddings/cc_examples_demonstrations_{dataset}.pkl\")\n",
    "        \n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "        \n",
    "        #Zero-shot and Few-shot random demonstrations:\n",
    "        for nr in [0, 1, 5]:\n",
    "            preds = []\n",
    "\n",
    "            for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "                messages = []\n",
    "                messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "                messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "\n",
    "                for i in range(0,nr):\n",
    "                    index = random.randint(0, len(train_examples)-1)\n",
    "                    messages.append(HumanMessage(content=f\"Classify these table columns: {train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_example_labels[index]}\"))\n",
    "\n",
    "                messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "                res = chat(messages)\n",
    "                preds.append(res.content)\n",
    "            save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-table-{nr}-shot.pkl\", preds)\n",
    "\n",
    "        # Few-shot similar demonstrations\n",
    "        for nr in [1, 5]:\n",
    "            preds = []\n",
    "\n",
    "            for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                messages = []\n",
    "                messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "                messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "\n",
    "                for index in examples_demonstrations[i][-nr:]:\n",
    "                    messages.append(HumanMessage(content=f\"Classify these table columns: {train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_example_labels[index]}\"))\n",
    "\n",
    "                messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "                res = chat(messages)\n",
    "                preds.append(res.content)\n",
    "            save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-table-{nr}-similar-shot.pkl\", preds)\n",
    "\n",
    "        # Few-shot corner-case demonstrations\n",
    "        preds = []\n",
    "        for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "            messages = []\n",
    "\n",
    "            #Task and instructions\n",
    "            messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "            messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "\n",
    "            # Add the 5 most similar training examples\n",
    "            for index in cc_examples_demonstratons[i]:\n",
    "                messages.append(HumanMessage(content=f\"Classify these table columns: {train_examples[index]}\"))\n",
    "                messages.append(AIMessage(content=f\"{train_example_labels[index]}\"))\n",
    "\n",
    "            messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "            res = chat(messages)\n",
    "            preds.append(res.content)\n",
    "        save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-table-4-cc-shot.pkl\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035897c",
   "metadata": {},
   "source": [
    "## Two-step Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365963fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_table_prediction(table_pred, domains):\n",
    "    cleaned_table_pred=\"-\"\n",
    "    for dom in domains:\n",
    "#     for dom in new_domains:\n",
    "        if dom in table_pred:\n",
    "            cleaned_table_pred = dom\n",
    "            break\n",
    "    return cleaned_table_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_messages = {\n",
    "    \"t1\": f\"Your task is to classify a table into one of these domains: \",\n",
    "    \"t2\": f\"You are a world-class data engineer and your task is to classify a table into one of these domains: \",    \n",
    "}\n",
    "\n",
    "instruction_messages = {\n",
    "    \"i1\": \"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. Decide the domain that best represents the table. 4. Answer with one domain.\",\n",
    "    \"i2\": \"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. Decide the domain that best represents the table. 4. Answer with one domain. 5. If you are not sure, pick the most likely domain.\",\n",
    "    \"i3\": \"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. Decide the domain that best represents the table. 4. Answer with one domain. 5. Answer only with the domains given to you!\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets[:2]:\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"\")    \n",
    "    # Load domain labels\n",
    "    domains = list(set(train_table_type_labels))\n",
    "    domains_list = \", \".join(domains)\n",
    "    labels_dict = {}\n",
    "    for dom in domains:\n",
    "        f = open(f\"../data/{dataset}-labels/{dataset}_{dom}_labels.txt\", 'r')\n",
    "        t = [line.split('\\n')[0] for line in f.readlines()]\n",
    "        labels_dict[dom] = t\n",
    "    \n",
    "    for model_name in models:\n",
    "        print(model_name)\n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "\n",
    "        #Few-shot and zero-shot random\n",
    "        for nr in [0, 1, 5]:\n",
    "            print(nr)\n",
    "            table_preds = []\n",
    "            preds = []\n",
    "\n",
    "            for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "                \n",
    "                #Step 1\n",
    "                messages = []\n",
    "                #Task and instructions\n",
    "                messages.append(SystemMessage(content=task_messages[\"t2\"]+f\" {domains_list}.\"))\n",
    "                messages.append(SystemMessage(content=instruction_messages[\"i2\"]))\n",
    "\n",
    "                for i in range(0, nr):\n",
    "                    index = random.randint(0, len(train_examples)-1)\n",
    "                    messages.append(HumanMessage(content=f\"Classify this table: {train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_table_type_labels[index]}\"))\n",
    "                    \n",
    "                messages.append(HumanMessage(content=f\"Classify this table:\\n{example}\"))\n",
    "\n",
    "                res = chat(messages)\n",
    "                table_preds.append(res.content)\n",
    "\n",
    "                clean_prediction = get_clean_table_prediction(res.content.strip(), domains)\n",
    "                                \n",
    "                # Step 2\n",
    "                messages = []\n",
    "                \n",
    "                #Show only a subset of labels related to the table type predicted\n",
    "                if clean_prediction != \"-\":\n",
    "                    labels_dom = \", \".join([labels_to_text[l] for l in labels_dict[clean_prediction]])\n",
    "                else:\n",
    "                    labels_dom = labels_joined\n",
    "                    \n",
    "                #Show only a subset of labels related to the table type predicted\n",
    "                messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_dom}.\"))\n",
    "                messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "                \n",
    "                \n",
    "                # Pick random demonstrations from the predicted table type in step one otherwise pick one from all the set\n",
    "                for m in range(0,nr):\n",
    "                    if clean_prediction != \"-\" and clean_prediction in train_table_type_labels:\n",
    "                        index = random.choice([j for j, e in enumerate(train_table_type_labels) if e == clean_prediction])\n",
    "                    else:\n",
    "                        index = random.randint(0, len(train_examples)-1)\n",
    "                    messages.append(HumanMessage(content=f\"Classify these table columns: {train_examples[index]}\"))\n",
    "                    messages.append(AIMessage(content=f\"{train_example_labels[index]}\"))\n",
    "                    \n",
    "                messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "                res = chat(messages)\n",
    "                preds.append(res.content)\n",
    "                \n",
    "\n",
    "            save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-two-step-{nr}-shot-step1.pkl\", table_preds)\n",
    "            save_pickle_file(f\"predictions/{dataset}/{model_name}/chat-two-step-{nr}-shot-step2.pkl\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f08f800",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-prompt evaluation\n",
    "for nr in [0, 1, 5]:\n",
    "    preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/chat-column-{nr}-shot.pkl\")\n",
    "    labels = [l for l in labels if l!=\"\"]\n",
    "    predictions, num = map_answers_column(preds)\n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if '-' in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table-prompt evaluation\n",
    "for nr in [0, 1, 5,\"5-similar\",\"4-cc\"]:\n",
    "    preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/chat-table-{nr}-shot.pkl\")\n",
    "    predictions, num = map_cta_labels(preds, test, text_to_label)\n",
    "    labels = [l for l in labels if l!=\"\"]\n",
    "    \n",
    "    predictions, num = map_cta_labels(preds)\n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if '-' in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845176e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sportstables table-prompt\n",
    "for nr in [0, 1, 5,\"5-similar\",\"4-cc\"]:\n",
    "    preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/chat-table-{nr}-shot.pkl\")\n",
    "    predictions, num = map_cta_labels(preds, test, text_to_label)\n",
    "    labels = [l for l in labels if l!=\"\"]\n",
    "    \n",
    "    predictions, num = map_sportstables(preds)\n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"] if '-' in predictions else types\n",
    "    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "    print(f\"{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5797d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for class_ in per_class_eval:\n",
    "    print(f\"{class_}: {per_class_eval[class_]['F1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d8006",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b5c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "errors_per_class = {}\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] != labels[i]:\n",
    "        errors += 1\n",
    "        print(f\"Predicted as {predictions[i]} when it was {labels[i]}\")\n",
    "        if labels[i] not in errors_per_class:\n",
    "            errors_per_class[labels[i]] = 0\n",
    "        errors_per_class[labels[i]] +=1\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558619f",
   "metadata": {},
   "source": [
    "### Re-load previous prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2aeacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/chat-table-0-shot.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c6aae",
   "metadata": {},
   "source": [
    "## Calculate tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b56c46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "import tiktoken\n",
    "def num_tokens_from_messages(messages, model):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ee8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_token_number = 0\n",
    "for model_name in [\"gpt-4-0613\"]:#\"gpt-3.5-turbo-0301\", \n",
    "    print(model_name)\n",
    "    for dataset in datasets[:1]:\n",
    "        print(dataset)\n",
    "        # Load dataset\n",
    "        examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"\")\n",
    "\n",
    "        for nr in [0]:\n",
    "            \n",
    "            for example in tqdm.tqdm(examples, total=len(examples)):\n",
    "                messages = []\n",
    "                \n",
    "                messages.append({\"role\":\"system\", \"content\":f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"})\n",
    "                messages.append({\"role\":\"system\", \"content\":\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"})\n",
    "                    \n",
    "                messages.append({\"role\":\"user\", \"content\":f\"Classify these table columns: {example}\"})\n",
    "                \n",
    "                total_token_number += num_tokens_from_messages(messages, model_name)\n",
    "\n",
    "print(total_token_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
