{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307f1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from utils import map_cpa_to_labels, calculate_f1_scores, save_pickle_file, load_pickle_file, load_cpa_dataset, decimal\n",
    "import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fe0620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load env file with API KEY using full path\n",
    "config = dotenv_values(\"/full/path/to/file/key.env\")\n",
    "os.environ['OPENAI_API_KEY'] = config[\"OPENAI_API_KEY\"]\n",
    "OPENAI_API_KEY = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "093763a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"sotabv2\", \"t2dv2-webtables\"]\n",
    "model_name = 'gpt-3.5-turbo-0301'\n",
    "# model_name = 'gpt-4-0613'\n",
    "chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b7ef6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_prompts = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"]\n",
    "tb_prompts = [\"TB1\", \"TB2\", \"TB3\", \"TB4\", \"TB5\", \"TB6\", \"TB7\"]\n",
    "inst_prompts = [\"I1\", \"I2\"]\n",
    "syst_prompts = [\"S1\", \"S2\", \"S3\", \"S5\"] #\"S4\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e82125",
   "metadata": {},
   "source": [
    "## Run generated definitions experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"\",False)\n",
    "    labels_joined = \", \".join([labels_to_text[l] for l in labels_to_text])\n",
    "    all_labels = [labels_to_text[l] for l in labels_to_text]\n",
    "\n",
    "    # Load embeddings\n",
    "    test_embeddings = load_pickle_file(f\"embeddings/cpa-test_embeddings_{dataset}.pkl\")\n",
    "    \n",
    "    # Run Test A prompts\n",
    "    for syst in syst_prompts:\n",
    "        for g in a_prompts:\n",
    "            if f\"cpa-{syst}_{g}-table-0-shot.pkl\" not in os.listdir(f\"predictions/{dataset}/{model_name}/\"):\n",
    "                print(f\"Loading knowledge {syst}_{g}\")\n",
    "                definitions = load_pickle_file(f\"knowledge/{model_name}/{dataset}/cpa-{syst}_{g}_prompt_knowledge.pkl\")\n",
    "                knowledge_embeddings = load_pickle_file(f\"embeddings/{model_name}/cpa-{syst}_{g}_knowledge_embeddings_{dataset}.pkl\")\n",
    "\n",
    "                examples_definitions = []\n",
    "                for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                    cos = cosine_similarity([test_embeddings[i]], knowledge_embeddings)\n",
    "                    cos_dict = {}\n",
    "                    for j, c in enumerate(cos[0]):\n",
    "                        cos_dict[j] = c\n",
    "                    sorted_cos_dict = {k: v for k, v in sorted(cos_dict.items(), key=lambda item: item[1])}\n",
    "                    examples_definitions.append(list(sorted_cos_dict.keys())[-10:])\n",
    "                \n",
    "                try:\n",
    "                    preds = []\n",
    "\n",
    "                    for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "                        messages = []\n",
    "\n",
    "                        knowledge_string = f\"\"\n",
    "                        for index in examples_definitions[j]:\n",
    "                            knowledge_string += f\"{all_labels[index]}: {definitions[index]}\\n\"\n",
    "                        knowledge_string = knowledge_string.strip()\n",
    "\n",
    "                        messages.append(SystemMessage(content=knowledge_string))\n",
    "\n",
    "                        #Task and instructions\n",
    "                        messages.append(SystemMessage(content=f\"Your task is to classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\"))\n",
    "                        messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column2: relationship. Don't return any relationship for the first column! 5. Answer only with labels from the provided label set!\"))\n",
    "                        messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "\n",
    "                        res = chat(messages)\n",
    "                        preds.append(res.content)\n",
    "                    save_pickle_file(f\"predictions/{dataset}/{model_name}/cpa-{syst}_{g}-table-0-shot.pkl\", preds)\n",
    "                except Exception:\n",
    "                    print(f\"Error in cpa-{syst}_{g}_{dataset}\")\n",
    "                    continue\n",
    "\n",
    "    # Run B prompts             \n",
    "    for tb in tb_prompts:\n",
    "        for syst in syst_prompts[:-1]: # skip last system for prompt b\n",
    "            if f\"cpa-{syst}_I_{tb}-table-0-shot.pkl\" not in os.listdir(f\"predictions/{dataset}/{model_name}/\"):\n",
    "                print(f\"Loading knowledge {syst}_I_{tb}\")\n",
    "                definitions = load_pickle_file(f\"knowledge/{model_name}/{dataset}/cpa-{syst}_I_{tb}_prompt_knowledge.pkl\")\n",
    "                knowledge_embeddings = load_pickle_file(f\"embeddings/{model_name}/cpa-{syst}_I_{tb}_knowledge_embeddings_{dataset}.pkl\")\n",
    "\n",
    "                examples_definitions = []\n",
    "                for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                    cos = cosine_similarity([test_embeddings[i]], knowledge_embeddings)\n",
    "                    cos_dict = {}\n",
    "                    for j, c in enumerate(cos[0]):\n",
    "                        cos_dict[j] = c\n",
    "                    sorted_cos_dict = {k: v for k, v in sorted(cos_dict.items(), key=lambda item: item[1])}\n",
    "                    examples_definitions.append(list(sorted_cos_dict.keys())[-10:])\n",
    "\n",
    "                try:\n",
    "                    preds = []\n",
    "\n",
    "                    for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "                        messages = []\n",
    "\n",
    "                        knowledge_string = f\"\"\n",
    "                        for index in examples_definitions[j]:\n",
    "                            knowledge_string += f\"{all_labels[index]}: {definitions[index]}\\n\"\n",
    "                        knowledge_string = knowledge_string.strip()\n",
    "\n",
    "                        messages.append(SystemMessage(content=knowledge_string))\n",
    "\n",
    "                        #Task and instructions\n",
    "                        messages.append(SystemMessage(content=f\"Your task is to classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\"))\n",
    "                        messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column2: relationship. Don't return any relationship for the first column! 5. Answer only with labels from the provided label set!\"))\n",
    "                        messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "\n",
    "                        res = chat(messages)\n",
    "                        preds.append(res.content)\n",
    "\n",
    "                    save_pickle_file(f\"predictions/{dataset}/{model_name}/cpa-{syst}_I_{tb}-table-0-shot.pkl\", preds)\n",
    "                except Exception:\n",
    "                    print(f\"Error in cpa-{syst}_I_{tb}_{dataset}.pkl\")\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee047253",
   "metadata": {},
   "source": [
    "## Run manual definitions experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c5e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"\",False)\n",
    "    all_labels = [labels_to_text[l] for l in labels_to_text]\n",
    "\n",
    "    f = open(f'../data/cpa-{dataset}-definitions.txt')\n",
    "    definitions = json.load(f)\n",
    "    all_labels = [labels_to_text[defn] for defn in definitions]\n",
    "    definitions = [definitions[defn] for defn in definitions]\n",
    "    test_embeddings = load_pickle_file(f'embeddings/cpa-test_embeddings_{dataset}.pkl')\n",
    "\n",
    "    # Pick the 10 most similar definitions for each example\n",
    "    knowledge_embeddings = load_pickle_file(f\"embeddings/cpa-{dataset}-definitions-embeddings.pkl\")\n",
    "    examples_definitions = []\n",
    "    for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "        cos = cosine_similarity([test_embeddings[i]], knowledge_embeddings)\n",
    "        cos_dict = {}\n",
    "        for j, c in enumerate(cos[0]):\n",
    "            cos_dict[j] = c\n",
    "        sorted_cos_dict = {k: v for k, v in sorted(cos_dict.items(), key=lambda item: item[1])}\n",
    "        examples_definitions.append(list(sorted_cos_dict.keys())[-10:])\n",
    "        \n",
    "    for model_name in [\"gpt-3.5-turbo-0301\",\"gpt-4-0613\"]:\n",
    "        print(model_name)\n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "        \n",
    "        preds = []\n",
    "\n",
    "        for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "            messages = []\n",
    "\n",
    "            knowledge_string = f\"\"\n",
    "            for index in examples_definitions[j]:\n",
    "                knowledge_string += f\"{all_labels[index]}: {definitions[index]}\\n\"\n",
    "            knowledge_string = knowledge_string.strip()\n",
    "\n",
    "            messages.append(SystemMessage(content=knowledge_string))\n",
    "\n",
    "            #Task and instructions\n",
    "            messages.append(SystemMessage(content=f\"Your task is to classify the relationship between two columns of a given table with one of the following relationships that are separated with comma: {labels_joined}.\"))\n",
    "            messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a relationship that best represents the relationship between that column and the first column of the table. 4. Answer with only one selected relationship for each column with the format Column2: relationship. Don't return any relationship for the first column! 5. Answer only with labels from the provided label set!\"))\n",
    "            messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "\n",
    "            res = chat(messages)\n",
    "            preds.append(res.content)\n",
    "\n",
    "        save_pickle_file(f\"predictions/{dataset}/{model_name}/cpa-manual-definitions-table-0-shot.pkl\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ffbe7",
   "metadata": {},
   "source": [
    "## Evaluate KG experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14ed88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    print(f\"\\tPrecision)\\tRecall\\tMacro-F1\\tMicro-F1\\tOOV\")\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cpa_dataset(dataset,\"\",False)\n",
    "    all_labels = [labels_to_text[l] for l in labels_to_text]\n",
    "    \n",
    "    # Evaluate A prompts\n",
    "    for syst in syst_prompts:\n",
    "        for g in a_prompts:\n",
    "            preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/cpa-{syst}_{g}-table-0-shot.pkl\")\n",
    "\n",
    "            predictions, num = map_cpa_to_labels(preds, test, text_to_label)\n",
    "        \n",
    "            types = list(set(labels))\n",
    "            types = types+[\"-\"] if '-' in predictions else types\n",
    "            evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "\n",
    "            print(f\"{syst}_{g}\\t{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")\n",
    "    \n",
    "    # Evaluate TB prompts\n",
    "    for tb in tb_prompts:\n",
    "        for syst in syst_prompts[:-1]: # skip last system for prompt b\n",
    "            preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/cpa-{syst}_I_{tb}-table-0-shot.pkl\")\n",
    "\n",
    "            predictions, num = map_cpa_to_labels(preds, test, text_to_label)\n",
    "\n",
    "            types = list(set(labels))\n",
    "            types = types+[\"-\"] if '-' in predictions else types\n",
    "            evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "\n",
    "            print(f\"{syst}_I_{tb}\\t{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d64820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
