{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307f1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from utils import map_cta_labels, calculate_f1_scores\n",
    "from utils import save_pickle_file, load_cta_dataset, load_pickle_file, decimal, map_sportstables\n",
    "import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fe0620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load env file with API KEY using full path\n",
    "config = dotenv_values(\"/full/path/to/file/key.env\")\n",
    "os.environ['OPENAI_API_KEY'] = config[\"OPENAI_API_KEY\"]\n",
    "OPENAI_API_KEY = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12131723",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"sotabv2\", \"t2dv2-webtables\", \"sportstables\"]\n",
    "models = [\"gpt-3.5-turbo-0301\", \"gpt-4-0613\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349e54c",
   "metadata": {},
   "source": [
    "## Manual definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe878c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"\")\n",
    "    all_labels = [labels_to_text[l] for l in labels_to_text]\n",
    "\n",
    "    f = open(f'../data/{dataset}-definitions.txt')\n",
    "    definitions = json.load(f)\n",
    "    all_labels = [labels_to_text[defn] for defn in definitions]\n",
    "    definitions = [definitions[defn] for defn in definitions]\n",
    "    test_embeddings = load_pickle_file(f'embeddings/test_embeddings_{dataset}.pkl')\n",
    "\n",
    "    # Pick the necessary deinitions for each example\n",
    "    knowledge_embeddings = load_pickle_file(f\"embeddings/{dataset}-definitions-embeddings.pkl\")\n",
    "    examples_demonstrations = []\n",
    "    for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "        cos = cosine_similarity([test_embeddings[i]], knowledge_embeddings)\n",
    "        cos_dict = {}\n",
    "        for j, c in enumerate(cos[0]):\n",
    "            cos_dict[j] = c\n",
    "        sorted_cos_dict = {k: v for k, v in sorted(cos_dict.items(), key=lambda item: item[1])}\n",
    "        examples_demonstrations.append(list(sorted_cos_dict.keys())[-10:])\n",
    "        \n",
    "    for model_name in [\"gpt-3.5-turbo-0301\",\"gpt-4-0613\"]:\n",
    "        print(model_name)\n",
    "        chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)\n",
    "        preds = []\n",
    "\n",
    "        for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "            messages = []\n",
    "\n",
    "            knowledge_string = f\"\"\n",
    "            for index in examples_demonstrations[j]:\n",
    "                knowledge_string += f\"{all_labels[index]}: {definitions[index]}\\n\"\n",
    "            knowledge_string = knowledge_string.strip()\n",
    "\n",
    "            messages.append(SystemMessage(content=knowledge_string))\n",
    "\n",
    "            #Task and instructions\n",
    "            messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "            messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))#\n",
    "            messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "\n",
    "            res = chat(messages)\n",
    "            preds.append(res.content)\n",
    "\n",
    "        save_pickle_file(f\"predictions/{dataset}/{model_name}/manual-definitions-table-0-shot.pkl\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e82125",
   "metadata": {},
   "source": [
    "## LLM definitions experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "093763a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-3.5-turbo-0301'\n",
    "# model_name = 'gpt-4-0613'\n",
    "chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7ef6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_prompts = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"]\n",
    "tb_prompts = [\"TB1\", \"TB2\", \"TB3\", \"TB4\", \"TB5\", \"TB6\", \"TB7\"]\n",
    "inst_prompts = [\"I1\", \"I2\"]\n",
    "syst_prompts = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4a814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets[:2]:\n",
    "    print(dataset)\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"\")\n",
    "    all_labels = [labels_to_text[l] for l in labels_to_text]\n",
    "\n",
    "    # Load embeddings\n",
    "    test_embeddings = load_pickle_file(f\"embeddings/test_embeddings_{dataset}.pkl\")\n",
    "    \n",
    "    # Run Test A prompts\n",
    "    for syst in syst_prompts:\n",
    "        for g in a_prompts:\n",
    "            if f\"{syst}_{g}-table-0-shot.pkl\" not in os.listdir(f\"predictions/{dataset}/{model_name}/\"):\n",
    "                print(f\"Loading knowledge {syst}_{g}\")\n",
    "                definitions = load_pickle_file(f\"knowledge/{model_name}/{dataset}/{syst}_{g}_prompt_knowledge.pkl\")\n",
    "                knowledge_embeddings = load_pickle_file(f\"embeddings/{model_name}/{syst}_{g}_knowledge_embeddings_{dataset}.pkl\")\n",
    "                \n",
    "                examples_demonstrations = []\n",
    "                for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                    cos = cosine_similarity([test_embeddings[i]], knowledge_embeddings)\n",
    "                    cos_dict = {}\n",
    "                    for j, c in enumerate(cos[0]):\n",
    "                        cos_dict[j] = c\n",
    "                    sorted_cos_dict = {k: v for k, v in sorted(cos_dict.items(), key=lambda item: item[1])}\n",
    "                    examples_demonstrations.append(list(sorted_cos_dict.keys())[-10:])\n",
    "                try:\n",
    "                    preds = []\n",
    "\n",
    "                    for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "                        messages = []\n",
    "\n",
    "                        knowledge_string = f\"\"\n",
    "                        for index in examples_demonstrations[j]:\n",
    "                            knowledge_string += f\"{all_labels[index]}: {definitions[index]}\\n\"\n",
    "                        knowledge_string = knowledge_string.strip()\n",
    "\n",
    "                        messages.append(SystemMessage(content=knowledge_string))\n",
    "                        #Task and instructions\n",
    "                        messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "                        messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values and definitions given to you in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "                        messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "\n",
    "                        res = chat(messages)\n",
    "                        preds.append(res.content)\n",
    "\n",
    "                    save_pickle_file(f\"predictions/{dataset}/{model_name}/{syst}_{g}-table-0-shot.pkl\", preds)\n",
    "                except Exception:\n",
    "                    print(f\"Error in {syst}_{g}_{dataset}.pkl\")\n",
    "                    continue\n",
    "                    \n",
    "    \n",
    "    # Run B prompts             \n",
    "    for tb in tb_prompts:\n",
    "        for syst in syst_prompts[:-1]: # skip last system for prompt b\n",
    "            for inst in inst_prompts:\n",
    "                if f\"{syst}_{inst}_{tb}-table-0-shot.pkl\" not in os.listdir(f\"predictions/{dataset}/{model_name}/\"):\n",
    "                    print(f\"Loading knowledge {tb}_{syst}_{inst}\")\n",
    "                    definitions = load_pickle_file(f\"knowledge/{model_name}/{dataset}/{syst}_{inst}_{tb}_prompt_knowledge.pkl\")\n",
    "                    knowledge_embeddings = load_pickle_file(f\"embeddings/{model_name}/{syst}_{inst}_{tb}_knowledge_embeddings_{dataset}.pkl\")\n",
    "\n",
    "                    examples_definitions = []\n",
    "                    for i, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "                        cos = cosine_similarity([test_embeddings[i]], knowledge_embeddings)\n",
    "                        cos_dict = {}\n",
    "                        for j, c in enumerate(cos[0]):\n",
    "                            cos_dict[j] = c\n",
    "                        sorted_cos_dict = {k: v for k, v in sorted(cos_dict.items(), key=lambda item: item[1])}\n",
    "                        examples_definitions.append(list(sorted_cos_dict.keys())[-10:])\n",
    "\n",
    "                    try:\n",
    "                        preds = []\n",
    "\n",
    "                        for j, example in tqdm.tqdm(enumerate(examples), total=len(examples)):\n",
    "\n",
    "                            messages = []\n",
    "\n",
    "                            knowledge_string = f\"\"\n",
    "                            for index in examples_definitions[j]:\n",
    "                                knowledge_string += f\"{all_labels[index]}: {definitions[index]}\\n\"\n",
    "                            knowledge_string = knowledge_string.strip()\n",
    "\n",
    "                            messages.append(SystemMessage(content=knowledge_string))\n",
    "\n",
    "                            #Task and instructions\n",
    "                            messages.append(SystemMessage(content=f\"You are a world-class data engineer and your task is to annotate the columns of a given table with only one of the following labels that are separated with comma: {labels_joined}.\"))\n",
    "                            messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values and definitions given to you in detail. 3. For each column, select a label that best represents the meaning of all cells in the column. 4. Answer with the selected label for each column using the format Column1: label. 5. Answer only with labels from the provided label set!\"))\n",
    "                            messages.append(HumanMessage(content=f\"Classify these table columns: {example}\"))\n",
    "\n",
    "                            res = chat(messages)\n",
    "                            preds.append(res.content)\n",
    "\n",
    "                        save_pickle_file(f\"predictions/{dataset}/{model_name}/{syst}_{inst}_{tb}-table-0-shot.pkl\", preds)\n",
    "                    except Exception:\n",
    "                        print(f\"Error in: {syst}_{inst}_{tb}_{dataset}.pkl\")\n",
    "                        continue\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f08f800",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2265f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets[:2]:\n",
    "    print(dataset)\n",
    "    print(f\"\\tPrecision)\\tRecall\\tMacro-F1\\tMicro-F1\\tOOV\")\n",
    "    # Load dataset\n",
    "    examples, labels, test_table_type_labels, train_examples, train_example_labels, train_table_type_labels, labels_to_text, text_to_label, labels_joined, train, test = load_cta_dataset(dataset,\"\")\n",
    "    if dataset == \"sportstables\":\n",
    "        labels = [l for l in labels if l != \"\"]\n",
    "    \n",
    "    for tb in tb_prompts:\n",
    "        for syst in syst_prompts[:-1]: # skip last system for prompt b\n",
    "            for inst in inst_prompts:\n",
    "                try:\n",
    "                    preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/{syst}_{inst}_{tb}-table-0-shot.pkl\")\n",
    "                    types = list(set(labels))\n",
    "\n",
    "                    if dataset == \"sportstables\":\n",
    "                        predictions, num = map_sportstables(preds, types, test)\n",
    "                    else:\n",
    "                        predictions, num = map_cta_labels(preds, test, text_to_label)\n",
    "                    \n",
    "                    types = types+[\"-\"] if '-' in predictions else types\n",
    "                    evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "\n",
    "                    print(f\"{syst}_{inst}_{tb}\\t{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")\n",
    "                except Exception:\n",
    "                    print(f\"Error in: {syst}_{inst}_{tb}-table-0-shot.pkl\")\n",
    "                    \n",
    "    for syst in syst_prompts:\n",
    "        for g in a_prompts:\n",
    "            try:\n",
    "                preds = load_pickle_file(f\"predictions/{dataset}/{model_name}/{syst}_{g}-table-0-shot.pkl\")\n",
    "                types = list(set(labels))\n",
    "\n",
    "                if dataset == \"sportstables\":\n",
    "                    predictions, num = map_sportstables(preds, types, test)\n",
    "                else:\n",
    "                    predictions, num = map_cta_labels(preds, test, text_to_label)\n",
    "\n",
    "                types = types+[\"-\"] if '-' in predictions else types\n",
    "                evaluation, per_class_eval = calculate_f1_scores(labels, predictions, len(types), types)\n",
    "\n",
    "                print(f\"{syst}_{g}\\t{decimal(evaluation['Precision'])}\\t{decimal(evaluation['Recall'])}\\t{decimal(evaluation['Macro-F1'])}\\t{decimal(evaluation['Micro-F1'])}\\t{num}\")\n",
    "            except Exception:\n",
    "                print(f\"Error in: {syst}_{g}-table-0-shot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03e845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
